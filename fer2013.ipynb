{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "g-tga0c_jPug",
    "outputId": "c296bcae-577c-49a1-dfb7-46609397965e"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "10U5BQDUjSdF",
    "outputId": "85f55a0e-5bad-4e6c-a82b-92a57d5c90a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n",
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
    "!apt-get update -qq 2>&1 > /dev/null\n",
    "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
    "\n",
    "# Generate auth tokens for Colab\n",
    "from google.colab import auth\n",
    "auth.authenticate_user()\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir('drive/My Drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "112dGnOSj6Xy",
    "outputId": "496e6419-114e-40a2-c3d9-e5e1a89c923a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fer2013/fer2013.csv\n",
      "fer2013/README\n",
      "fer2013/fer2013.bib\n",
      "fer2013/\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "d7NJe5ielu0T",
    "outputId": "94e36c0b-6d12-43bc-9d57-de9d21a4ca71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of instances:  35888\n",
      "instance length:  2304\n"
     ]
    }
   ],
   "source": [
    "with open(\"fer2013/fer2013.csv\") as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "lines = np.array(content)\n",
    "\n",
    "num_of_instances = lines.size\n",
    "print(\"number of instances: \",num_of_instances)\n",
    "print(\"instance length: \",len(lines[1].split(\",\")[1].split(\" \")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "p1=pd.read_csv('fer2013/fer2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emotion                                             pixels     Usage\n",
       "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
       "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
       "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
       "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
       "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3LbF7Mhdmblf"
   },
   "outputs": [],
   "source": [
    "num_classes = 7 #angry, disgust, fear, happy, sad, surprise, neutral\n",
    "batch_size = 256\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1DR6LUf7mA2r"
   },
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = [], [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KR97kS7omIwN"
   },
   "outputs": [],
   "source": [
    "for i in range(1,num_of_instances):\n",
    "    \n",
    "        emotion, img, usage = lines[i].split(\",\")\n",
    "          \n",
    "        val = img.split(\" \")\n",
    "            \n",
    "        pixels = np.array(val, 'float32')\n",
    "        \n",
    "        emotion = keras.utils.to_categorical(emotion, num_classes)\n",
    "    \n",
    "        if 'Training' in usage:\n",
    "            y_train.append(emotion)\n",
    "            x_train.append(pixels)\n",
    "        elif 'PublicTest' in usage:\n",
    "            y_test.append(emotion)\n",
    "            x_test.append(pixels)\n",
    " \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "_j1qI9n7mMSa",
    "outputId": "56005b86-668c-4543-9f02-aadf34c7c34a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28709 train samples\n",
      "3589 test samples\n"
     ]
    }
   ],
   "source": [
    "#data transformation for train and test sets\n",
    "x_train = np.array(x_train, 'float32')\n",
    "y_train = np.array(y_train, 'float32')\n",
    "x_test = np.array(x_test, 'float32')\n",
    "y_test = np.array(y_test, 'float32')\n",
    "\n",
    "x_train /= 255 #normalize inputs between [0, 1]\n",
    "x_test /= 255\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 48, 48, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 48, 48, 1)\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-zLa-lDJmml9"
   },
   "outputs": [],
   "source": [
    "#construct CNN structure\n",
    "model = Sequential()\n",
    "\n",
    "#1st convolution layer\n",
    "model.add(Conv2D(64, (5, 5), activation='relu', input_shape=(48,48,1)))\n",
    "model.add(MaxPooling2D(pool_size=(5,5), strides=(2, 2)))\n",
    "\n",
    "#2nd convolution layer\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "#3rd convolution layer\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D(pool_size=(3,3), strides=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "#fully connected neural networks\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "#------------------------------\n",
    "#batch process\n",
    "gen = ImageDataGenerator()\n",
    "train_generator = gen.flow(x_train, y_train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1975
    },
    "colab_type": "code",
    "id": "dEUiLfcqJk8A",
    "outputId": "b3bbd2bc-3180-4019-8676-1bc34d91875b"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1627\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1628\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,128].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-500455024ef0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    203\u001b[0m                                         \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m                                         data_format=self.data_format)\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/layers/pooling.py\u001b[0m in \u001b[0;36m_pooling_function\u001b[0;34m(self, inputs, pool_size, strides, padding, data_format)\u001b[0m\n\u001b[1;32m    266\u001b[0m         output = K.pool2d(inputs, pool_size, strides,\n\u001b[1;32m    267\u001b[0m                           \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                           pool_mode='max')\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mpool2d\u001b[0;34m(x, pool_size, strides, padding, data_format, pool_mode)\u001b[0m\n\u001b[1;32m   3976\u001b[0m         x = tf.nn.max_pool(x, pool_size, strides,\n\u001b[1;32m   3977\u001b[0m                            \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3978\u001b[0;31m                            data_format=tf_data_format)\n\u001b[0m\u001b[1;32m   3979\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpool_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'avg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3980\u001b[0m         x = tf.nn.avg_pool(x, pool_size, strides,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(value, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   2138\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2139\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2140\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mmax_pool\u001b[0;34m(input, ksize, strides, padding, data_format, name)\u001b[0m\n\u001b[1;32m   4639\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m   4640\u001b[0m         \u001b[0;34m\"MaxPool\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4641\u001b[0;31m         data_format=data_format, name=name)\n\u001b[0m\u001b[1;32m   4642\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4643\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 instructions)\n\u001b[0;32m--> 488\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[1;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3272\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3273\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3274\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3275\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3276\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1790\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[1;32m   1791\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[0;32m-> 1792\u001b[0;31m                                 control_input_ops)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m     \u001b[0;31m# Initialize self._outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 2 for 'max_pooling2d_4/MaxPool' (op: 'MaxPool') with input shapes: [?,2,2,128]."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 581
    },
    "colab_type": "code",
    "id": "VXee8BvPnHaV",
    "outputId": "cdfbae73-4c6c-48ea-cc2e-c939bc7f4d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 44, 44, 64)        1664      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 18, 18, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 5, 5, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 3, 3, 128)         147584    \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 1, 1, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 1799      \n",
      "=================================================================\n",
      "Total params: 331,783\n",
      "Trainable params: 331,783\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBruHmpNnMPu"
   },
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n-73kHPpHCgQ"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKoUp8K1G9no"
   },
   "outputs": [],
   "source": [
    "early_stops = EarlyStopping(patience=3, monitor='val_acc')\n",
    "checkpointer = ModelCheckpoint(filepath='weights_dip.best.eda.hdf5', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2237
    },
    "colab_type": "code",
    "id": "vf89R426nPna",
    "outputId": "95a14b06-2db3-4c48-91d8-7d78c15ff72a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28709 samples, validate on 3589 samples\n",
      "Epoch 1/30\n",
      "28709/28709 [==============================] - 253s 9ms/step - loss: 1.8235 - acc: 0.2474 - val_loss: 1.8066 - val_acc: 0.2516\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.80664, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 2/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 1.7812 - acc: 0.2573 - val_loss: 1.7324 - val_acc: 0.2962\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.80664 to 1.73237, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 3/30\n",
      "28709/28709 [==============================] - 249s 9ms/step - loss: 1.6834 - acc: 0.3179 - val_loss: 1.6526 - val_acc: 0.3419\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.73237 to 1.65262, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 4/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 1.5961 - acc: 0.3667 - val_loss: 1.5518 - val_acc: 0.3937\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.65262 to 1.55176, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 5/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.5198 - acc: 0.4093 - val_loss: 1.5016 - val_acc: 0.4166\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.55176 to 1.50162, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 6/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.4626 - acc: 0.4303 - val_loss: 1.4411 - val_acc: 0.4347\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.50162 to 1.44110, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 7/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.4070 - acc: 0.4562 - val_loss: 1.4023 - val_acc: 0.4578\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.44110 to 1.40233, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 8/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 1.3585 - acc: 0.4766 - val_loss: 1.3316 - val_acc: 0.4868\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.40233 to 1.33158, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 9/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.3256 - acc: 0.4875 - val_loss: 1.3137 - val_acc: 0.4898\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.33158 to 1.31369, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 10/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 1.2841 - acc: 0.5057 - val_loss: 1.2933 - val_acc: 0.4993\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.31369 to 1.29334, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 11/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.2474 - acc: 0.5244 - val_loss: 1.2989 - val_acc: 0.5099\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 1.29334\n",
      "Epoch 12/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 1.2215 - acc: 0.5327 - val_loss: 1.2732 - val_acc: 0.5149\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.29334 to 1.27316, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 13/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.1928 - acc: 0.5451 - val_loss: 1.2510 - val_acc: 0.5210\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.27316 to 1.25103, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 14/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 1.1686 - acc: 0.5529 - val_loss: 1.2681 - val_acc: 0.5191\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 1.25103\n",
      "Epoch 15/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.1557 - acc: 0.5585 - val_loss: 1.2163 - val_acc: 0.5436\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.25103 to 1.21634, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 16/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.1271 - acc: 0.5711 - val_loss: 1.2150 - val_acc: 0.5419\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.21634 to 1.21497, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 17/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 1.1163 - acc: 0.5784 - val_loss: 1.1879 - val_acc: 0.5553\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.21497 to 1.18792, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 18/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.0799 - acc: 0.5924 - val_loss: 1.1856 - val_acc: 0.5536\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.18792 to 1.18560, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 19/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.0553 - acc: 0.6021 - val_loss: 1.1814 - val_acc: 0.5609\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.18560 to 1.18139, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 20/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 1.0421 - acc: 0.6067 - val_loss: 1.1683 - val_acc: 0.5628\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.18139 to 1.16827, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 21/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 1.0179 - acc: 0.6158 - val_loss: 1.1559 - val_acc: 0.5704\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.16827 to 1.15590, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 22/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 1.0083 - acc: 0.6200 - val_loss: 1.1826 - val_acc: 0.5676\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 1.15590\n",
      "Epoch 23/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 0.9858 - acc: 0.6276 - val_loss: 1.1557 - val_acc: 0.5748\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.15590 to 1.15568, saving model to weights_dip.best.eda.hdf5\n",
      "Epoch 24/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 0.9581 - acc: 0.6363 - val_loss: 1.2125 - val_acc: 0.5645\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 1.15568\n",
      "Epoch 25/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 0.9379 - acc: 0.6463 - val_loss: 1.1883 - val_acc: 0.5720\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 1.15568\n",
      "Epoch 26/30\n",
      "28709/28709 [==============================] - 251s 9ms/step - loss: 0.9146 - acc: 0.6565 - val_loss: 1.1874 - val_acc: 0.5740\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 1.15568\n",
      "Epoch 27/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 0.9037 - acc: 0.6612 - val_loss: 1.2181 - val_acc: 0.5690\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 1.15568\n",
      "Epoch 28/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 0.8769 - acc: 0.6729 - val_loss: 1.1976 - val_acc: 0.5676\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 1.15568\n",
      "Epoch 29/30\n",
      "28709/28709 [==============================] - 252s 9ms/step - loss: 0.8471 - acc: 0.6843 - val_loss: 1.2151 - val_acc: 0.5773\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 1.15568\n",
      "Epoch 30/30\n",
      "28709/28709 [==============================] - 250s 9ms/step - loss: 0.8276 - acc: 0.6882 - val_loss: 1.1805 - val_acc: 0.5860\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 1.15568\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb01399e208>"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=30, batch_size=256, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "JXJpZMFrnh3t",
    "outputId": "2a62fa7a-ce1b-47d8-ff59-556c5a5f6958"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3589/3589 [==============================] - 9s 2ms/step\n",
      "Test loss: 1.180547374475298\n",
      "Test accuracy: 58.59570911200341\n"
     ]
    }
   ],
   "source": [
    "#overall evaluation\n",
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', 100*score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k8CLA3do4pWe"
   },
   "outputs": [],
   "source": [
    "model.save('models/emotion_model.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WcrC_znrq018"
   },
   "outputs": [],
   "source": [
    "#function for drawing bar chart for emotion preditions\n",
    "def emotion_analysis(emotions):\n",
    "    objects = ('angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    \n",
    "    plt.bar(y_pos, emotions, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('percentage')\n",
    "    plt.title('emotion')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YUgZQJsfq7a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "monitor_testset_results = False\n",
    "from keras.models import load_model\n",
    "model = load_model('emotion_model.hdf5')\n",
    "\n",
    "if monitor_testset_results == True:\n",
    "\t\n",
    "\tpredictions = model.predict(x_test)\n",
    "  \n",
    "  \n",
    "\n",
    "\tindex = 0\n",
    "\tfor i in predictions:\n",
    "\t\tif index < 30 and index >= 20:\n",
    "\t\t\t#print(i) #predicted scores\n",
    "\t\t\t#print(y_test[index]) #actual scores\n",
    "\t\t\t\n",
    "\t\t\ttesting_img = np.array(x_test[index], 'float32')\n",
    "\t\t\ttesting_img = testing_img.reshape([48, 48]);\n",
    "\t\t\t\n",
    "\t\t\tplt.gray()\n",
    "\t\t\tplt.imshow(testing_img)\n",
    "\t\t\tplt.show()\n",
    "\t\t\t\n",
    "\t\t\tprint(i)\n",
    "\t\t\t\n",
    "\t\t\temotion_analysis(i)\n",
    "\t\t\tprint(\"----------------------------------------------\")\n",
    "\t\tindex = index + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "colab_type": "code",
    "id": "qEfhFl4Kq_Wj",
    "outputId": "b87597c5-336d-4daf-a30e-dee271dff878"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andro\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras_preprocessing\\image.py:492: UserWarning: grayscale is deprecated. Please use color_mode = \"grayscale\"\n",
      "  warnings.warn('grayscale is deprecated. Please use '\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJztnX2sltW55q9bpJWiolhAvgQE/CqKRmoxNtb60XbwVG3Tj9OetDYhIU2dtCfnTI50Jk7nJDOJ/lF7knZypmRqZJrTg5yjKcae6QTth7UqH4JaERG0FTZs+UZFWyu45o/9esJzrQve5cve797bdf0SAmtxv8+z3ud57/2897Xv+16RUoIxpi5OGOwFGGO6jx3fmAqx4xtTIXZ8YyrEjm9MhdjxjakQO74xFWLHN6ZCjsvxI+JTEbEpIrZExOL+WpQxZmCJTjP3ImIEgOcBXAegB8AaAF9KKT17tNeMGDEijRw5sjF3+PDhxvj9739/9rq33367MVZrPnToUGN84oknZjZ87tNPPz2zOfnkk495bnWuP/zhD5nNCSe0/5mqjs1ERDY3YsSIxlhdD36dsuE5dS6+P8pO3bP3ve99jbG6Hzz31ltvZTa7d+9ujEePHp3ZjB8/vjFW95Xfa6ef+/7KdB2o4/T09GDfvn35jSTyu1HOZQC2pJReBICIWAbgRgBHdfyRI0di6tSpjbnXXnutMZ4xY0b2uj/96U/HHAPAnj17GuMPfvCDmc3EiRMb489//vOZzRVXXNEY//GPf8xs+MO4cOHCzOYDH/hANseO/uabb2Y27GjsQABw2mmntT3OqFGjGmN1zfgHGP9AAfL7o9Y0ffr0zGbatGmNsbofPLd9+/bMZsmSJY3x3LlzM5tbbrmlMVb3la+R+qGrfsgxymE7eV3Ja0rg4yxYsKDodcfzVX8ygG1HjHtac8aYIc7xPPHV14nsx2FELAKwCNBf94wx3ed4nvg9AI783j4FwA42SiktSSnNSynNU18ljTHd53gewWsAzI6IGQC2A/hLAF8+1gtSSllsxd8CSr4VlMRn6ofMG2+80Rjv3Lkzs2Hhav/+/ZnNbbfddszjArngBADXXntt2/M///zzjfG2bdsyG16jEuUYJTayDvHKK69kNpMmTcrm+P0eOHCg7evWr1+f2bCeoq4jaz779u3LbB544IHG+Morr8xsxowZ0xir66E+V+/VsvWOHT+ldCgi/iOA/wdgBIC7Ukob+m1lxpgB47iC7pTSvwH4t35aizGmSzhzz5gK6arMHhFtkzZUEgejYrGZM2c2xvw7agA49dRTG2MVv7I28OUv57IFr/Hyyy/PbObPn5/NnXPOOY2x0gF6e3sb4xUrVmQ2GzdubIzV7/H//Oc/N8bqenCiy4QJEzIb9ft31iY4ZwDIY2j+vT4APPfcc40xJ1gBeY6A0hM4R0HlA3CMXxq7l+gn/Jku+R290hhKEqr4s8/HKVkv4Ce+MVVixzemQuz4xlSIHd+YChn0HFoWmEoEDSUAnnLKKY2xSkZhgUeJWVxpN2/evMyGE0S4aOZoc5deemljrAQmFtNWrVqV2WzY0EyXUNeMBT91rr179zbGLAgCWqg666yzjnkuABg3blxjfNJJJ2U2Dz/8cGP8+uuvZzb8OiUA7tjRTBhVyUIXXXRRY6zEzprwE9+YCrHjG1MhdnxjKqTrCTyccMBxtirCKGlgwXMqQYK76zz44IOZzc9//vPG+Mwzz8xsOD6cPXt2ZsMJRUBeFMMFOUCeHPPYY49lNvw+eAzksblqqMHNS1RilCokYl2GtRMA+P3vf98Yv/rqq5kNd+5RcTfPqe46nEDD2gEAfOELX2iMVYMTVSDG16Ska5IqEOP3oXSZkq5JbMP3uTQxyU98YyrEjm9MhdjxjakQO74xFdJVcU914OGxShhhwUIlcZQkZHBSz9q1a9seR4lSPT09jbGqslMJK1u3bm2Mly1bltmsWbOmMVaCk+rgy5SISbzGl19+ObNR1Xn8PsaOHZvZcBXd+eefn9mwuLdly5bMpuR+cJWleh/c3UeJewNJiXDXTfzEN6ZC7PjGVIgd35gK6XqMzzFbyQ4nbKOKa0piWi7mOHjwYGZTEvvxGtVuO6o77ve///3GeNOmTZkNJx6dccYZmQ1rHCo5hwte1PVgrUDtiFNyjZQNaxOsCwB5jK8SX0q60vD51T3krkUf+chHMpuSpJrSDjcM39eSjr6ddE92Bx5jzFGx4xtTIXZ8YyrEjm9MhXRV3DvhhBOypBEW5Uqqn1RyDAs8SihiEU4lg/A23iqBhjvQqP3hv/vd72ZzLDCV7CWoOvlwtyFV0VjS4rmTyjMgv2cqoYiFVLVNN3ckKtnKW90Pbt2tOjRxxZ4S97pJ6RZeA3b+rp3JGDNksOMbUyF2fGMqpOtddlVs0w6O/VRs3G5rISBPalHFJcyUKVOyuZKYcvXq1dkcJ94orYLnVJEMr/vxxx/PbEqKlvg6qvdR0pVGvQ/WJlT8yh2NWbsAgN27d7c9F7+OtyEDOkuOUZQkGakCHJ4r2UKrJObvOKGoo1cZY4Y1dnxjKsSOb0yF2PGNqZCuV+dxEk27hB6gfUthNaeEEd4iSiXeMKeeemo2x+KaSmBRFXu8RiWc8ftXCTx8fnUcFkTVdeUqNiV28lZYQN5yu0RIVPeDRTlVZcjXTF1XTmB65JFHMpsPfehDjbESAJWQ2u1OPd3CT3xjKsSOb0yFtHX8iLgrInZFxDNHzI2NiJURsbn1d769iTFmyFIS498N4AcA/s8Rc4sBPJRSuj0iFrfGt7Y7UES03TZJxYucNMEdU4E8OUYV4HCChIrN2UbFfdxV9/77789s1JbPnLRR8l6VDjFnzpxjrgfIi2SUDjB69OjGWOkJXJAEdNbRWMH3aOLEiZkNb8WlEl/4OKqT0MqVKxvj8847L7P5xCc+kc3x/SgpflJ00mW3JMmnk4Q4oOCJn1J6GACXf90IYGnr30sB3NTR2Y0xg0KnMf6ElFIvALT+zh85xpghy4D/Oi8iFgFYBOiNMIwx3afTJ/7OiJgIAK2/dx3NMKW0JKU0L6U0r6TxhDFm4On0iX8/gJsB3N76e0XJi0aOHJkJOFx9pRI9uEJOtXMuqWxiUVAl54waNaoxVgIgJx3dfvvtmU0nrZEVSgTiPeJVkg0nuihxj9+rumbqGrEw9uSTT7ZdI1fiAXk1oFojJ12NGTMms2FR8uSTT85snn322cZYbdf16U9/OpsrqfrspHNOSSvvgdxmq+TXef8M4DEA50ZET0QsRJ/DXxcRmwFc1xobY4YJbZ/4KaUvHeW/runntRhjuoQz94ypkK534GE4IaLTBImS47C4yPEjkMe0Ksbn4hIlWvK2X0BnHVZ27cp1Uy4cmTlzZmbDyTkq6amks5GKl/n9X3TRRZkNbyW+Z8+ezIaTfFQBDsfUJfH7ZZddltnMmDGjMeYOv0CuNwF54VKJLtNp5xw+dqe+UIKf+MZUiB3fmAqx4xtTIXZ8Yyqkq+Le4cOHM0GHBS+VjKK2Vmpno6raWLxSCSMTJkw45hjI16wSilRVX0l77RIBkoWzefPmZTbLly9vexyu4Dtw4EBmo/jkJz/ZGH/84x/PbFio27RpU2bDgp9KzmFeeumlbI4Fv23btmU2nASmWom/8MIL2RxXPpYId0oA5M+aEu5Y8FNiazvBr7Tdtp/4xlSIHd+YCrHjG1MhdnxjKqSr4t7bb7+diXAslihRjLPXlNjHmWpKBClpOc3nVy2nN2/e3BirbDIl8LCYp8RFFgBVBiBXvqm21Jyppq4rC2VKAFTZbCX72s+dO7cxVlV+LF6p+8GZk/v3789sLr/88sb4+eefz2z4eijxd+vWrdkcZwGW7Ns4kPD5Oz23n/jGVIgd35gKseMbUyGDXp3Hca5KrOB4vdMWXhxnqv3YufJt0qRJmc3kyZMbY465AZ1Iwccu2Z5JxdicMHTmmWdmNrfe2ux2fscdd2Q2Z599dmOs2lurKrYNGzY0xh/72McyG9ZcOIEGAJ5++unGWGkFHMOqtuk8pyoq2UZ1BFLVgawFKB2E9ZxOq/NKOvDwsR3jG2OKseMbUyF2fGMqxI5vTIV0VdyLiLZCiEpY6aQFkRI9WExTYhbbKDGJRTElSKqEFT62SiLhY6n3wfvBz5o1K7M544wzGuPrrrsus+GEFSU4sUgH5GJiyT1TSUZ8PpUIxWKa2pSFbdT94JbgqhJPiaTcskwJsgPVXnsg8RPfmAqx4xtTIXZ8Yyqk6zE+x0icpKASJBgV83Ncp47DRTKq4wsnf6j4lYtJ1P70ipIiHY4X1fvYu3dv2+NwbM5dcwDgd7/7XWO8Zs2azEbFy7xGdR35vqpEJL6PvBWWOja30gaAnTt3NsYq6WratGmN8SOPPJLZTJ06NZvjGF/pMkx/tc7ur1be8tgdvcoYM6yx4xtTIXZ8YyrEjm9MhXRV3Bs5cmTWrppbLKuKJJ5TnVrYRoknLJSVVIMpcYvPVdJOGSjrOMPrVtdj+/btx3wNUCb6sJCpuvQocZMr7dQa+dqqvfP4GqnjvPjii42x2gOQr/+5556b2XAiVm9vb2ajriOLeSXCnbr2A7nXfSf4iW9MhdjxjakQO74xFTLoCTyMirM4PlLxEseiKu7mDiuqAIeTbNS2UnwcFdOVFFyoeLWk2xB3+VUFMHyNlM1jjz3WGCtdQiUQcaKNeq/cJYgLi9T5lJ7Anxe1Ru7CzGMAuOSSSxpj1VlI6RB8r1UhUVeLa+hzXeIb8jj9tiJjzLDBjm9MhdjxjamQto4fEVMj4pcRsTEiNkTEt1rzYyNiZURsbv2dt5o1xgxJSsS9QwD+NqW0LiJOAfBERKwE8DUAD6WUbo+IxQAWA7j1GMdBRLRN2ihpKawEQJ5TggsnlajtmEraKasuMIwSqjqxUUk+vG4leD311FONsdpXnoVDlaxU0iVI2fB9VMcuSWjive5VK2++HmoLrW984xuN8YMPPpjZPPzww9nc1772tWxuKMFiX6nQ2PaJn1LqTSmta/37NQAbAUwGcCOApS2zpQBuKl+uMWYweVcxfkRMB3AJgFUAJqSUeoG+Hw4AZFF6RCyKiLURsbbkCWeMGXiKHT8iTgZwL4C/TinlvwA/CimlJSmleSmleSVNDIwxA09RAk9EjESf0/9TSum+1vTOiJiYUuqNiIkA8qwJIqXUdgugkuISpQNwrKMSeDiG5CQToCwRiOdKY+PXX3/9mOsB8sIZpTHw69S5Vq1a1XaNvB6VXKX0FO7Oyx19gTzRRcWerE2o61GyXdqOHTsaY/X54GSpK664IrNZt25dNleiL/F7U58ZXtNgF/uUqPoB4EcANqaU7jziv+4HcHPr3zcDWNEvKzLGDDglT/wrAHwFwO8i4snW3H8GcDuA5RGxEMBWAJ8fmCUaY/qbto6fUnoEwNF+R3BN/y7HGNMNnLlnTIV0tTovpZQl0ZSIckyJMFJio6qxuHuLqsbiqj6V0FPS3Ue1ky7pNsSVbqqC8IILLmiMf/KTn2Q2vGWUOtcpp5ySzbFQqPaV52uiRDE+nxIy+Zpx9SQAnH56+6TRjRs3NsaqOo/FTgDYtGlTYzxu3LjMhtc0kN12+HNdIn4q/MQ3pkLs+MZUiB3fmArpaox/wgknZDEzx9klMb6CY52SrjjqXCUFKBz3liTZAPnW2Uo/4NepxBs+3xNPPJHZzJ8/vzG+++67MxtOalFddlU3G05yUnE3x7lKB+GEIXXPWBtQBUl8P9SW4MuXL2+MP/zhD2c2apvsFSua6SnqdZ1kpKrPXkmhGeMttIwxxdjxjakQO74xFWLHN6ZCut5em0UNFn1KBI0SAbAkiaJkmysl3PGxlY1aI4tQo0aNymxYzFMiIScHPfroo5nNzJkzszmGE5GUSKXuB7fqVtd6y5YtjbFKVuKEGZWMwsLh6tWrMxtOVuJttwBgzZo1jbFqbT558uRs7qqrrmp77Isvvjib6xZ8zfqtA48x5r2HHd+YCrHjG1MhdnxjKqSr4t7hw4czYUiJV0xJiyZ1LoYFN3UcFhtV5hwfR2WuqYo1zlTjFlZAXnl3/vnnZzYs7qlz3XnnnY3xnDlzMhtuQ62q0yZOnJjN8bVVLbuWLl3aGCsBkK+/uh/q2jKcEaleM2HChMZY7SXIIiEAfPSjH22Mf/CDH2Q2XOmnPjP8/jvdb7FrrbeMMe897PjGVIgd35gK6XoHnnbVVp3E/AoVZ3EMpWJTjp9L4i6VeKKq0Xp7e9sem/UDVR03fnxz75Jbbrkls+FEF27bDQBjxoxpjLnbDACMHTs2m+N7pO7Hr3/967bnVzoMU1J1yQlU6n1wjH/fffdlNqrlNp//+uuvz2x4Oy51nJL22t3ET3xjKsSOb0yF2PGNqRA7vjEV0vXqPBZLuCKs01ZC6lydUJLkw6gqOyVcvfLKK42xasHNraJVld/UqVMbY7V3HbeRUkImt4rmFtQAMGvWrGyO75GqTmRxVSXM8HGUSMjHUTZ8ftVCi9ucqfWo1mMsyp133nmZzV133dUYT5o0KbPhyj91P5iBFAD9xDemQuz4xlSIHd+YCulqjP/6669j7dq1jTkucChJ6iihpJhBJflwTK+Sc9hGtVz+zW9+k82VdODhAhMV03J8qjrncHGPKuThWHT79u2ZzQsvvND22CVtsRX8OnXP+Dgl7cbnzp2b2fA2Y6oluYrN+fpz0hOQJ/Woa8Z6zrRp0zIbleQ0UPiJb0yF2PGNqRA7vjEVYsc3pkK6Ku4dOnQIL7/8cmOOExlU22NGJbWwUKTEJU6IUDY8p5JsuEvOZz7zmcxGtYEu6SbDqASanp6exnjVqlWZzYUXXtgYK5GQ3yt3mwGAH//4x9kcVx6qY7NQpZJ8SuB9+lggVeeaN29eZsMtyPkaAroSkbv7qM8eJ1CpVuIlHXiYEoG040S1jl5ljBnW2PGNqZC2jh8RJ0XE6oh4KiI2RMTft+ZnRMSqiNgcEfdERPvkY2PMkKAkxn8TwNUppYMRMRLAIxHxfwH8DYDvpZSWRcT/ArAQwD8e60ARkcX0HDOpGKpkyyx1rk7gc6mEEY69VHGHiuc5NlZdejgWVDEt6yB79+7NbA4ePNgYq7iT40xVOLJjx462a+QCGCCPuzlWL4WvEcfcQL5upTmwVqPumbpGJR2A+F6XJI+pz3QnyWuddt1t61Gpj3c+RSNbfxKAqwH8a2t+KYCbOlqBMabrFD1KI2JERDwJYBeAlQBeAHAgpfRO7moPgHzHQWPMkKTI8VNKh1NKFwOYAuAyAPkuD33fAjIiYlFErI2Itf21GYAx5vh4V8FzSukAgF8BmA/gtIh4J5iaAiAPBvtesySlNC+lNG+wO4saY/poK+5FxDgAb6WUDkTEKADXArgDwC8BfA7AMgA3A1jR7lgppUzkYSFGiSclyQ5cMVeS5FPSzUVVvnFVnaqy4046CpWsxOtWVVwrV65sjFULbj62Eht5bv/+/ZmNEuW4A5CCuw2V3ENlw8Kduq78Ok4SU+tRQqYSWxklwPHr1DdbfugpG54byG/IJar+RABLI2IE+r4hLE8pPRARzwJYFhH/HcB6AD8asFUaY/qVto6fUnoawCVi/kX0xfvGmGGGM/eMqZCuFukAg7t1EJ9bFY5w4onqssvbSSsdQBX3sBagrgXHq+rYvIWWis03bNjQGF9++eVtz6U6x6i4m9ekuvv0V3zKOozSZTgZZ/r06ZnND3/4w8ZYbf9dsuaSbc/6q1P0QOInvjEVYsc3pkLs+MZUiB3fmArpurjXSaVdf8HCjEq8YcGvpGJq9OjR2Zx6Hb93tY0TJ97ce++9bc+nhMQ9e/Y0xitW5PlVXMH32c9+NrNRW0bx+VVbbl5TSXKMgqvjZsyYkdlwQpHaCoy7JnGLcECLlFx5qD6//LnqtENUN/ET35gKseMbUyF2fGMqpOvbZHP8U9J9lZM2VEzLqGQMPrfqHMNzKn7nLjBqmy1O8gHy96GScxhVcMIJKup6/OIXv2iMv/KVr2Q28+fPb4xVbKpiYY5pv/Od72Q2nAilOhnxcVTiCxcJqYIkPrbSKvi+qk4+6p6pDkjt6LTQrKSQh+m0sMdPfGMqxI5vTIXY8Y2pEDu+MRUy6NV5nSTMlFAi7inhhvc/V51reI1KuFGVbiVVXGxTIgCqPdu/+c1vNsZz5szJbJTgxqg927mbzW9/+9vMht9bSStxBQuiqjru2muvbYzVNeOOOzNnzsxsVHttRp1/OPaS9BPfmAqx4xtTIXZ8YyqkqzF+SimL/davX98Yn3POOdnruAuO6sLCNioW43hVbaPEWyWrrZNLCjdUd9yS5CWORZUOwbGoeq9nn312Y3zgwIHMRiUwMWeeeWbbNarzs01JHKwSoVhP+eIXv5jZPPfcc42x6gLM74O3tj4anXTHLeky1alNu3OVdrjyE9+YCrHjG1MhdnxjKsSOb0yFdD2Bh9m5c2djrKrBWPQpSfIp6fRTsq2UEsD42EpQUd19GCVSclceVR3IQqYSxV566aXGWImEJe2+1ftfu3ZtY6zeBx+r08Qsvh+qI9ATTzzRGK9bty6zYUFUJet02iVoOOInvjEVYsc3pkLs+MZUiB3fmAoZdHGPRaASoUjZcEagErw4c09l5U2aNKntuUrahSkxjcUjtS8fozLuuG3U448/ntnw3nCXXnppZsPnV5V4SvBavHhxY9zpPoGdVLWpqsdNmzY1xtu2bctsvv71rzfGSmzkbENlN5DVo93ET3xjKsSOb0yF2PGNqZBBj/E5Fu+kKwuQx6uqCwvHsFOmTMlsJk+e3BirCj5O4FFxn5rjdSsdouTYvb29jbFKROIuOSVbP6k4XG0rxW2olZ7Bmou6r2yjzs9VdKzBAMD48eMbY6VLsC7y7LPPZjbcyhsY3C3fBpL35rsyxhwTO74xFVLs+BExIiLWR8QDrfGMiFgVEZsj4p6IyH8XYowZkrybJ/63ABy5//AdAL6XUpoNYD+Ahf25MGPMwFEk7kXEFADXA/gfAP4m+lSYqwF8uWWyFMB/A/CP73YBLKioJAoW5UqSL5QNi2Cq8o2r0ZSQyAkrau95RUk7axa81Pl5j3gl7nHrL/VeeU6JjSVrLhEylU1JleOFF17YGLNoCeTJSU899VRm88wzzzTGV155ZWajBOGSJKsSQbqktXoJ/ZX4U/rE/wcAfwfgndWeAeBASumdq9IDYLJ6oTFm6NHW8SPiLwDsSikdWfSsOvrJH0URsSgi1kbEWvX/xpjuU/JV/woAN0TEAgAnATgVfd8ATouIE1tP/SkAdqgXp5SWAFgCABEx/LYcMeY9SFvHTyl9G8C3ASAirgLwn1JKfxUR/wLgcwCWAbgZQNtANyKyWIdjcxVncryokipKYh/eakolnpTE+Py6e+65J7NR7Zv5WCVxniokOuussxpjlYjE7bVVAQ5rA2+88UZmc9NNN2VzJbE538eSe6ZsWGN49NFHMxvWXBYtWpTZ8HudNWtWZlPSmlrds9KW1kOJ4/k9/q3oE/q2oC/m/1H/LMkYM9C8q5TdlNKvAPyq9e8XAVzW/0syxgw0ztwzpkLs+MZUyKBX55W0YWYbVX3FAo8SYVhcU4Igi1JKuGGhqKRrkDqfWiMnkZSIhFx5BuTto1UCDx9HiXv79u3L5ri7Tknii3qv7YReANi/f39jrPbF40q72bNnZzbcxl0l5qhOQiVCZicoIbNE7O238/fLUYwxwwo7vjEVYsc3pkIGPcbnOLOkg62ipOMLJ4McPHgwsylJKuH4sKS7DZBrE8qmpCiEbV599dXMpmTPdr7WN9xwQ1sbINcUSjQO1cmH16i2HePEo/Xr12c2c+fObYxVJx3e9uvcc8/NbFTy2GB3wx0o/MQ3pkLs+MZUiB3fmAqx4xtTIYMu7rF4pJJz2EYl+ZQk8LDAxG2igVw4U+thEYhbcqtzqdeVCIcKTrRRAhyfX10Pft2ePXsyG5Wcw8dSiTe8xpKEppJzqe2xrrrqqsZ4zZo1mQ133Cm5r0B+P0rEPvVeSxLVOqHThB4/8Y2pEDu+MRVixzemQgY9xi8pXOE4SxWTcLysYmVO2FFxOM+pmI5j4wULFmQ2P/3pT9uuUVGS0MRzu3fvzmx4jrsPAcBtt93WGKtYXSXDcCKUSuBRcwzH2aqTECcLqZiW17h3797MRm29VTN+4htTIXZ8YyrEjm9MhdjxjamQQRf3SrqOdLJHuXoNC3dqOyYWipS4xoke11xzTWbzs5/9LJtjMUsJkLxudf5du3Yd8zVALmRu3Lgxs+np6Wl7LiVucvKJ6lxT0qWIUdV5fM2U2MjvVSUC8Zy6ZiqpptOtrtqhkoVKknrcgccY0zF2fGMqxI5vTIUMeoxfEvt1EuMrOBZViUA8p7aJ5nhRvYeXX345m+MkEhXn8XstiWnVNtncHXf58uWZDW8XptajYlyORVUHIN7mSyUH8bVV8St3B1bH2bp1a2P81a9+NbNhfYffe234iW9MhdjxjakQO74xFWLHN6ZCopvtgyNiN4CXAHwQQN7uZWgzHNcMDM91e82dMy2lNK6dUVcd/99PGrE2pTSv6yc+DobjmoHhuW6veeDxV31jKsSOb0yFDJbjLxmk8x4Pw3HNwPBct9c8wAxKjG+MGVz8Vd+YCum640fEpyJiU0RsiYjF3T5/CRFxV0TsiohnjpgbGxErI2Jz6+/TB3ONTERMjYhfRsTGiNgQEd9qzQ/ZdUfESRGxOiKeaq3571vzMyJiVWvN90REnqA/yETEiIhYHxEPtMZDfs1H0lXHj4gRAP4ngP8A4AIAX4qIC7q5hkLuBvApmlsM4KGU0mwAD7XGQ4lDAP42pXQ+gPkAbmld26G87jcBXJ1SmgvgYgCfioj5AO4A8L3WmvcDWDiIazwa3wJwZHeT4bDmf6fbT/zLAGxJKb2YUvozgGUAbuzyGtqSUnoYwD6avhHA0ta/lwK4qauLakNKqTeltK7179fQ96GcjCG87tTHO6WGI1t/EoCrAfxra35IrRkAImIKgOsB/O/WODDE18x02/EnAzhy87Oe1txwYEJKqRfoczIA4wd5PUey7WADAAABr0lEQVQlIqYDuATAKgzxdbe+Mj8JYBeAlQBeAHAgpfROX7Kh+Bn5BwB/B+CdmuUzMPTX3KDbjq8ahvnXCv1IRJwM4F4Af51SygvlhxgppcMppYsBTEHfN8LzlVl3V3V0IuIvAOxKKT1x5LQwHTJrVnS7EUcPgKlHjKcA2NHlNXTKzoiYmFLqjYiJ6HtCDSkiYiT6nP6fUkr3taaH/LoBIKV0ICJ+hT594rSIOLH1BB1qn5ErANwQEQsAnATgVPR9AxjKa87o9hN/DYDZLQX0fQD+EsD9XV5Dp9wP4ObWv28GsGIQ15LRijN/BGBjSunOI/5ryK47IsZFxGmtf48CcC36tIlfAvhcy2xIrTml9O2U0pSU0nT0fX5/kVL6KwzhNUtSSl39A2ABgOfRF8v9l26fv3CN/wygF8Bb6PuWshB9cdxDADa3/h472OukNX8UfV8vnwbwZOvPgqG8bgAXAVjfWvMzAP5ra/5sAKsBbAHwLwDeP9hrPcr6rwLwwHBa8zt/nLlnTIU4c8+YCrHjG1MhdnxjKsSOb0yF2PGNqRA7vjEVYsc3pkLs+MZUyP8HgxZi5VWlMFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "img = image.load_img(\"sad1.jpg\", grayscale=True, target_size=(48, 48))\n",
    "\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "\n",
    "x /= 255\n",
    "\n",
    "custom = model.predict(x)\n",
    "emotion_analysis(custom[0])\n",
    "\n",
    "x = np.array(x, 'float32')\n",
    "x = x.reshape([48, 48]);\n",
    "\n",
    "plt.gray()\n",
    "plt.imshow(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPNVHqBn2rGD"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Copy of fer2013.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
